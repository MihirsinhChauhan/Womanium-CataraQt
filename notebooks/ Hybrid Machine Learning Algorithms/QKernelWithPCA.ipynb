{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e523bd4",
   "metadata": {},
   "source": [
    "# Image Classification using Quantum Kernel and SVC\n",
    "\n",
    "This program demonstrates the implementation of Quantum kernel-based training of a Support Vector classifier.The kernel, which is a small building block of the algorithm, is computed by a quantum device and is executed repetitively. For quantum machine learning applications with many parameters, kernel-based training can be a great alternative to the variational approach to quantum machine learning.\n",
    "\n",
    "Normal and cataract eye images are converted to grayscale, resized to 28X28 and their dimensionality further reduced through kernel principal component analysis, which captures the non-linear features and pares down the dimensions to say, 4 to 6. This  number decides the number of qubuts in the quantum kernel. The quantum kernel is given by the mutual overlap of two data-encoding quantum states. In this example, angle-encoding is used to prepare the two states and the quantum node is used as a quantum kernel evaluator. The Support Vector Machine is trained using the kernel matrix with the labelled training data.   \n",
    "\n",
    "Ref: Pennylane demo 'Kernel-based training of quantum models with scikit-learn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7df77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n",
    "from pennylane.operation import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856e8560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.templates import RandomLayers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21a9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import get_custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75673411",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "IMG_HEIGHT =28\n",
    "IMG_WIDTH = 28\n",
    "\n",
    "# eye_diseases_classification dataset\n",
    "IMG_ROOT = 'D:\\Womanium2023\\GlobalQuantumProject\\Datasets\\eye_diseases_classification\\Proc\\\\'\n",
    "IMG_DIR = [IMG_ROOT+'normal',\n",
    "           IMG_ROOT+'cataract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b9864b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Womanium2023\\\\GlobalQuantumProject\\\\Datasets\\\\eye_diseases_classification\\\\Proc\\\\normal',\n",
       " 'D:\\\\Womanium2023\\\\GlobalQuantumProject\\\\Datasets\\\\eye_diseases_classification\\\\Proc\\\\cataract']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b812c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44c8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(0,\n",
    "                  columns=['paths',\n",
    "                           'cataract'],\n",
    "                  index=range(2500))\n",
    "\n",
    "filepaths = glob.glob(IMG_ROOT + '*/*')\n",
    "\n",
    "for i, filepath in enumerate(filepaths):\n",
    "    filepath = os.path.split(filepath)\n",
    "    df.iloc[i, 0] = filepath[0] + '/' + filepath[1]\n",
    "\n",
    "    if filepath[0] == IMG_DIR[0]:    # normal\n",
    "            df.iloc[i, 1] = 0\n",
    "    elif filepath[0] == IMG_DIR[1]:  # cataract\n",
    "            df.iloc[i, 1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb535ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normal and cataract images\n",
      "cataract\n",
      " 0    1562\n",
      "-1     938\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of normal and cataract images')\n",
    "print(df['cataract'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "917802ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.paths !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "259bcff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df,\n",
    "                                     test_size=0.2,\n",
    "                                     random_state=SEED,\n",
    "                                     stratify=df['cataract'])\n",
    "\n",
    "train_df, val_df = train_test_split(train_df,\n",
    "                                    test_size=0.15,\n",
    "                                    random_state=SEED,\n",
    "                                    stratify=train_df['cataract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7006a254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1367/1367 [00:00<00:00, 8493.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 242/242 [00:00<00:00, 7874.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 403/403 [00:00<00:00, 7427.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def create_datasets(df):\n",
    "    imgs = []\n",
    "\n",
    "    for path in tqdm(df['paths']):\n",
    "        #print(path)\n",
    "        img = cv2.imread(path,0)\n",
    "        img = cv2.resize(img,(IMG_HEIGHT,IMG_WIDTH))\n",
    "        img=img.flatten() #convert 2d to 1d array\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.array(imgs, dtype='float32')\n",
    "\n",
    "    labels = df.cataract\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "train_imgs, train_labels = create_datasets(train_df)\n",
    "val_imgs, val_labels = create_datasets(val_df)\n",
    "test_imgs, test_labels = create_datasets(test_df)\n",
    "\n",
    "train_imgs = train_imgs / 255.0\n",
    "val_imgs = val_imgs / 255.0\n",
    "test_imgs = test_imgs / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a716e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "057836ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30   # Number of optimization epochs\n",
    "n_layers = 1    # Number of random layers\n",
    "n_train = 1000   # Size of the train dataset\n",
    "n_test = 50     # Size of the test dataset\n",
    "\n",
    "SAVE_PATH = \"eyeQCNN1/\" # Data saving folder\n",
    "PREPROCESS = False           # If False, skip quantum processing and load data from SAVE_PATH\n",
    "np.random.seed(0)           # Seed for NumPy random number generator\n",
    "tf.random.set_seed(0)       # Seed for TensorFlow random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "338eacc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataset size\n",
    "train_images = train_imgs[:n_train]\n",
    "train_labels = train_labels[:n_train]\n",
    "test_images = test_imgs[:n_test]\n",
    "test_labels = test_labels[:n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ec7ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "#from sklearn import preprocessing\n",
    "\n",
    "kernel_pca = KernelPCA(\n",
    "    n_components=4, kernel=\"rbf\", gamma=None, fit_inverse_transform=True, alpha=0.1\n",
    ")\n",
    "\n",
    "# rescale the data so it has unit standard deviation and zero mean.\n",
    "#scaler = preprocessing.StandardScaler().fit(data)\n",
    "#data = scaler.transform(data)\n",
    "\n",
    "X_train= kernel_pca.fit(train_images).transform(train_images)\n",
    "testfit = kernel_pca.transform(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "146007fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = len(X_train[0])\n",
    "n_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac45402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_kernel = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "projector = np.zeros((2**n_qubits, 2**n_qubits))\n",
    "projector[0, 0] = 1\n",
    "\n",
    "@qml.qnode(dev_kernel, interface=\"autograd\")\n",
    "def kernel(x1, x2):\n",
    "    \"\"\"The quantum kernel.\"\"\"\n",
    "    AngleEmbedding(x1, wires=range(n_qubits))\n",
    "    qml.adjoint(AngleEmbedding)(x2, wires=range(n_qubits))\n",
    "    return qml.expval(qml.Hermitian(projector, wires=range(n_qubits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19257773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel(X_train[0], X_train[0])#sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a0404ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_matrix(A, B):\n",
    "    \"\"\"Compute the matrix whose entries are the kernel\n",
    "       evaluated on pairwise data from sets A and B.\"\"\"\n",
    "    return np.array([[kernel(a, b) for b in B] for a in A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62f39820",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=kernel_matrix).fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab21e34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svm.predict(testfit)\n",
    "accuracy_score(predictions, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
